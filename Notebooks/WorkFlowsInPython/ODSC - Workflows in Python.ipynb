{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflows in Python\n",
    "Description : This notebook was made to following along with the articles written by Caitlin Malone on ODSC. Through these articles, Caitlin works with data collected for the \"Pump it Up: Data Mining the Water Table\" drivendata competition [[Link](https://www.drivendata.org/competitions/7/)] .\n",
    "\n",
    "[Link to Article (Part 1)](https://www.opendatascience.com/blog/preprocessing-data-a-python-workflow-part-1/)\n",
    "\n",
    "### Part 1 Notes\n",
    "\n",
    "- read in data\n",
    "- transformed features and labels to make the data amenable to machine learning\n",
    "- picked a modeling strategy (classification)\n",
    "- made a train/test split (this was done implicitly when I called cross_val_score)\n",
    "- evaluated several models for identifying wells that are failed or in danger of failing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows in Python Part 1: Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import wget\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving the Data (Just in case links break)\n",
    "# wget.download('https://s3.amazonaws.com/drivendata/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv', out='train_features.csv')\n",
    "# wget.download('https://s3.amazonaws.com/drivendata/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv', out='train_labels.csv')\n",
    "# wget.download('https://s3.amazonaws.com/drivendata/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv', out='test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "features_df = pd.read_csv('https://s3.amazonaws.com/drivendata/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv')\n",
    "labels_df = pd.read_csv('https://s3.amazonaws.com/drivendata/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv')\n",
    "test_set_values = pd.read_csv('https://s3.amazonaws.com/drivendata/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 2 columns):\n",
      "id              59400 non-null int64\n",
      "status_group    59400 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 928.2+ KB\n"
     ]
    }
   ],
   "source": [
    "labels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id    status_group\n",
      "0  69572      functional\n",
      "1   8776      functional\n",
      "2  34310      functional\n",
      "3  67743  non functional\n",
      "4  19728      functional\n",
      "5   9944      functional\n",
      "6  19816  non functional\n",
      "7  54551  non functional\n",
      "8  53934  non functional\n",
      "9  46144      functional\n"
     ]
    }
   ],
   "source": [
    "print( labels_df.head(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mapping\n",
    "map_dict = {\"functional\": 2,\n",
    "            \"functional needs repair\": 1,\n",
    "            \"non functional\": 0\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  status_group\n",
      "0  69572             2\n",
      "1   8776             2\n",
      "2  34310             2\n",
      "3  67743             0\n",
      "4  19728             2\n"
     ]
    }
   ],
   "source": [
    "labels_df['status_group'] = labels_df['status_group'].map(map_dict)\n",
    "print( labels_df.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding out which columns are object type and oneHotEncoder in sklearn or get_dummies() in pandas.\n",
    "\n",
    "list_of_columns = list(features_df.columns)\n",
    "cols_to_transform = []\n",
    "\n",
    "for col in list_of_columns:\n",
    "    if features_df[col].dtype == 'object':\n",
    "        cols_to_transform.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_feature( df, column_name ):\n",
    "    unique_values = set( df[column_name].tolist() )\n",
    "    transformer_dict = {}\n",
    "    for ii, value in enumerate(unique_values):\n",
    "        transformer_dict[value] = ii\n",
    "    df[column_name] = df[column_name].map( transformer_dict )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in cols_to_transform:\n",
    "    features_df = transform_feature( features_df, column )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  amount_tsh  date_recorded  funder  gps_height  installer  longitude  \\\n",
      "0  69572      6000.0             10      96        1390        115  34.938093   \n",
      "1   8776         0.0             69     318        1399        124  34.698766   \n",
      "2  34310        25.0            255    1702         686       1176  37.460664   \n",
      "3  67743         0.0            319    1336         263        258  38.486161   \n",
      "4  19728         0.0            194     189           0       1482  31.130847   \n",
      "\n",
      "    latitude  wpt_name  num_private          ...            payment_type  \\\n",
      "0  -9.856322     12813            0          ...                       3   \n",
      "1  -2.147466     22016            0          ...                       6   \n",
      "2  -3.821329     23714            0          ...                       2   \n",
      "3 -11.155298      1242            0          ...                       6   \n",
      "4  -1.825359      7360            0          ...                       6   \n",
      "\n",
      "   water_quality  quality_group  quantity  quantity_group  source  \\\n",
      "0              3              2         3               3       1   \n",
      "1              3              2         0               0       0   \n",
      "2              3              2         3               3       2   \n",
      "3              3              2         2               2       9   \n",
      "4              3              2         4               4       0   \n",
      "\n",
      "   source_type  source_class  waterpoint_type  waterpoint_type_group  \n",
      "0            1             2                4                      3  \n",
      "1            0             0                4                      3  \n",
      "2            4             0                2                      3  \n",
      "3            2             2                2                      3  \n",
      "4            0             0                4                      3  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print( features_df.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_df.drop(\"date_recorded\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'amount_tsh' 'funder' 'gps_height' 'installer' 'longitude' 'latitude'\n",
      " 'wpt_name' 'num_private' 'basin' 'subvillage' 'region' 'region_code'\n",
      " 'district_code' 'lga' 'ward' 'population' 'public_meeting' 'recorded_by'\n",
      " 'scheme_management' 'scheme_name' 'permit' 'construction_year'\n",
      " 'extraction_type' 'extraction_type_group' 'extraction_type_class'\n",
      " 'management' 'management_group' 'payment' 'payment_type' 'water_quality'\n",
      " 'quality_group' 'quantity' 'quantity_group' 'source' 'source_type'\n",
      " 'source_class' 'waterpoint_type' 'waterpoint_type_group']\n"
     ]
    }
   ],
   "source": [
    "print(features_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = features_df.as_matrix()\n",
    "y = labels_df[\"status_group\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This splits my data into three equal portions, trains on two of them, and tests on the third. This process repeats three times. Thatâ€™s why three numbers get printed in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63560606  0.64883838  0.645     ]\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72792929  0.73222222  0.72580808]\n",
      "[ 0.78489899  0.78429293  0.78323232]\n"
     ]
    }
   ],
   "source": [
    "## DecisionTree and RandomForest\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
